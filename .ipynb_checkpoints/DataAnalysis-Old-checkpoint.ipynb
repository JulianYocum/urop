{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import uproot as up\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from scipy import stats\n",
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "pwd = \".\"\n",
    "#pwd = str(Path().absolute())\n",
    "#pwd = \"/nfs/cuore1/scratch/yocum\"\n",
    "\n",
    "class DataAnalysis:\n",
    "    def __init__(self, auto=False, load=False, eventfile=None, clusterfile=None): \n",
    "        \n",
    "        if load:\n",
    "            self.eventdf = pd.read_csv(eventfile)\n",
    "            self.clusterdf = pd.read_csv(clusterfile)\n",
    "        \n",
    "        else:\n",
    "            self.eventdf = self.load_data()\n",
    "            #self.clusterdf = self.make_clusterDF(self.eventdf)\n",
    "\n",
    "\n",
    "            if auto:\n",
    "                self.filter_noisy()\n",
    "                self.filter_baseline()\n",
    "                self.arrange_clusters(5, 1.0) # >= 5 events, <= 1.0 seconds\n",
    "                self.make_clusterDF()\n",
    "                self.filter_clusterdf(2.5, 0) # <= 1.5 NRMSE, >= 0 channels\n",
    "            \n",
    "    \n",
    "    def save_dfs(self, eventfile, clusterfile):\n",
    "        self.eventdf.to_csv(eventfile, index=False)\n",
    "        self.clusterdf.to_csv(clusterfile, index=False)\n",
    "    \n",
    "    \n",
    "    def load_data(self):\n",
    "        frames = []\n",
    "        path = pwd + '/data/ds3564/'\n",
    "        \n",
    "        #num_towers = len(os.listdir(path))\n",
    "        num_towers = 19\n",
    "        filename = 'ds3564Tower'\n",
    "\n",
    "        for t in range(1, num_towers + 1):\n",
    "            new_path = path + filename + str(t) + '.root'\n",
    "\n",
    "            #load tower\n",
    "            event = up.open(new_path)['tree']\n",
    "\n",
    "            #recast the data as a pandas dataframe and append to frames\n",
    "            frames.append(event.pandas.df())\n",
    "\n",
    "        raw = pd.concat(frames)\n",
    "        \n",
    "        #adjust variable from milli to seconds\n",
    "        raw['MaxPosInWindow'] = raw['MaxPosInWindow'] / 1000.0\n",
    "        \n",
    "        \n",
    "        run_starttimes = self.runstarttimes()\n",
    "        \n",
    "        for run in raw['Run'].unique():\n",
    "            raw.loc[raw['Run'] == run, ['Time']] += run_starttimes[run]\n",
    "        \n",
    "        return raw\n",
    "\n",
    "    \n",
    "    def runstarttimes(self):\n",
    "\n",
    "        times = {}\n",
    "\n",
    "        # fix times\n",
    "        with open(pwd + \"/data/ds3564_start_stop_times.txt\") as f:\n",
    "            f.readline()\n",
    "            f.readline()\n",
    "\n",
    "            first = True\n",
    "\n",
    "            for line in f:\n",
    "                linedata = line.split('|')\n",
    "                linedata = [i.lstrip().rstrip() for i in linedata]\n",
    "\n",
    "                if linedata[2] == \"Background\" and linedata[6] == \"OK (0)\":\n",
    "\n",
    "                    linedate = datetime.strptime(linedata[3], \"%b %d, %Y %H:%M:%S%z\")\n",
    "                    #print(linedate.timestamp())\n",
    "                    timestamp = linedate.replace(tzinfo=timezone.utc).timestamp()\n",
    "\n",
    "                    # save first run timestamp\n",
    "                    if first:\n",
    "                        first_timestamp = timestamp\n",
    "                        first = False\n",
    "\n",
    "                    times[int(linedata[1])] = timestamp - first_timestamp\n",
    "        return times\n",
    "    \n",
    "    \n",
    "    def get_eventdf(self):\n",
    "        return self.eventdf\n",
    "    \n",
    "    \n",
    "    def eventsperchannel(self):\n",
    "        # get num events per channel\n",
    "        events = []\n",
    "        for c in range(1,max(self.eventdf['Channel']) + 1):\n",
    "            events.append(len(self.eventdf[self.eventdf['Channel'] == c]))\n",
    "        return events\n",
    "    \n",
    "    \n",
    "    # find dead channels\n",
    "    def deadchannels(self):\n",
    "        channel_events = self.eventsperchannel()\n",
    "        \n",
    "        ch = []\n",
    "        for c in range(1,max(self.eventdf['Channel']) + 1):     \n",
    "            if channel_events[c - 1] == 0:\n",
    "                ch.append(c)\n",
    "\n",
    "        #for c in range()\n",
    "        return ch\n",
    "    \n",
    "    \n",
    "    #detect outliers using above threshold IQR\n",
    "    def noisychannels(self):\n",
    "        threshold = 5 \n",
    "        \n",
    "        channel_events = self.eventsperchannel()        \n",
    "        Q1, Q3 = np.percentile(channel_events, 25), np.percentile(channel_events, 75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        upper_bound = Q3 + IQR * threshold\n",
    "        return [c for c in range(1,max(self.eventdf['Channel']) + 1) if channel_events[c - 1] > upper_bound]\n",
    "\n",
    "    \n",
    "    def filter_noisy(self):\n",
    "        self.eventdf = self.eventdf[np.isin(self.eventdf['Channel'], self.noisychannels(), invert=True)]\n",
    "        \n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def filter_baseline(self):\n",
    "        self.eventdf = self.eventdf[(self.eventdf['Baseline'] + self.eventdf['MaxToBaseline']) > 9000]\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    \n",
    "    def arrange_clusters(self, e_thresh, t_thresh):\n",
    "        \n",
    "        e_thresh = int(e_thresh)\n",
    "        t_thresh = float(t_thresh)\n",
    "        \n",
    "        sorted_df = self.eventdf.copy()\n",
    "        \n",
    "        sorted_df['MaxTime'] =  self.eventdf[['Time', 'MaxPosInWindow']].sum(axis=1) # sort by 'Time' + 'MaxPosInWindow'\n",
    "        #sorted_df['MaxTime'] =  self.eventdf[['Time', 'OFdelay']].sum(axis=1) # sort by 'Time' + 'MaxPosInWindow'\n",
    "        #sorted_df['MaxTime'] = self.eventdf['Time'] # Sort by 'Time'\n",
    "        \n",
    "        \n",
    "        sorted_df = sorted_df.sort_values(by=['MaxTime'])\n",
    "        sorted_df = sorted_df.reset_index(drop=True)\n",
    "\n",
    "        new_df = sorted_df.copy()\n",
    "\n",
    "        #print(new_df[50:70])\n",
    "\n",
    "        new_df['Cluster'] = [-1]*len(new_df)\n",
    "\n",
    "        #get events that are clustered\n",
    "        row = 0\n",
    "        events = 1\n",
    "        cluster = [row]\n",
    "        cluster_num = 0\n",
    "\n",
    "        while (row < len(self.eventdf)):\n",
    "\n",
    "            #make sure there is a next event. if at end of dataframe, set times to fail next test\n",
    "            if(row < len(self.eventdf) - 1):\n",
    "                successive_time = sorted_df.iloc[row + 1]['MaxTime'] #+ sorted_df.iloc[row + 1]['MaxPosInWindow']/1000.0\n",
    "                event_time = sorted_df.iloc[row]['MaxTime'] #+ sorted_df.iloc[row]['MaxPosInWindow']/1000.0\n",
    "            else:\n",
    "                event_time = 0\n",
    "                successive_time = t_thresh + 1\n",
    "\n",
    "\n",
    "            if abs(successive_time - event_time) <= t_thresh:\n",
    "                events += 1\n",
    "                cluster.append(row + 1)\n",
    "            else:   \n",
    "\n",
    "                #print(events)\n",
    "                if events < e_thresh:\n",
    "                    for i in cluster:\n",
    "                        new_df = new_df.drop(i) #sorted_df.index[i])\n",
    "                else:\n",
    "                    #clusters.append(cluster)\n",
    "                    for i in cluster:\n",
    "                        #print(cluster_num)\n",
    "                        new_df.loc[i, 'Cluster'] = cluster_num\n",
    "                    cluster_num += 1\n",
    "\n",
    "                events = 1\n",
    "                cluster = [row + 1]\n",
    "\n",
    "            row += 1\n",
    "        \n",
    "        self.eventdf = new_df\n",
    "    \n",
    "        return self\n",
    "\n",
    "\n",
    "    # create dictionary mapping channel numbers to a tuple containing coordinates (x,y,z)\n",
    "    def load_coords(self):\n",
    "\n",
    "        coords = {}\n",
    "\n",
    "        with open(pwd + \"/data/detector_positions.txt\", 'r') as f:\n",
    "            for line in f:\n",
    "                data = line.split(',')\n",
    "\n",
    "                if int(data[0]) < 1000:\n",
    "                    coords[int(data[0])] = (float(data[1]), float(data[2]), float(data[3]))\n",
    "\n",
    "        return coords\n",
    "\n",
    "    # returns array of 3 arrays corresponding to x y z\n",
    "    def clustercoords(self, cluster):\n",
    "\n",
    "        ch_coords = self.load_coords()\n",
    "\n",
    "        #coords = []\n",
    "        x = []\n",
    "        y = []\n",
    "        z = []\n",
    "\n",
    "        for c in cluster['Channel']:\n",
    "            #coords.append([ch_coords[c][0], ch_coords[c][1], ch_coords[c][2]])\n",
    "            x.append(ch_coords[c][0])\n",
    "            y.append(ch_coords[c][1])\n",
    "            z.append(ch_coords[c][2])\n",
    "\n",
    "        return [x,y,z]\n",
    "\n",
    "    \n",
    "    # takes dataframe of a single cluster and finds line of best fit\n",
    "    def fitline(self, cluster):\n",
    "        coords = self.clustercoords(cluster)\n",
    "\n",
    "        data  = np.array(coords).T\n",
    "\n",
    "        datamean = data.mean(axis=0)\n",
    "\n",
    "        # Do an SVD on the mean-centered data.\n",
    "        uu, dd, vv = np.linalg.svd(data - datamean)\n",
    "\n",
    "        # Now vv[0] contains the first principal component, i.e. the direction\n",
    "        # vector of the 'best fit' line in the least squares sense.\n",
    "\n",
    "        # Now generate some points along this best fit line, for plotting.\n",
    "\n",
    "        # I use -7, 7 since the spread of the data is roughly 14\n",
    "        # and we want it to have mean 0 (like the points we did\n",
    "        # the svd on). Also, it's a straight line, so we only need 2 points.\n",
    "        linepts = vv[0] * np.mgrid[-400:400:2j][:, np.newaxis]\n",
    "\n",
    "        # shift by the mean to get the line in the right place\n",
    "        linepts += datamean\n",
    "\n",
    "        return linepts\n",
    "    \n",
    "    \n",
    "    def clusterNRMSE(self, cluster):\n",
    "        ''' gets NRMSE for a given cluster\n",
    "            use distance from point to line of best fit as residual where\n",
    "            d = |(p-a)x(p-b)|/|b-a|\n",
    "            and variables are vectors'''\n",
    "\n",
    "        # get dictionary of all channels coords\n",
    "        channel_coords = self.load_coords()\n",
    "\n",
    "        dlist = []\n",
    "\n",
    "        # store 2 best fit lines as vectors\n",
    "        a = self.fitline(cluster)[0]\n",
    "        b = self.fitline(cluster)[1]\n",
    "\n",
    "        for index, event in cluster.iterrows():\n",
    "\n",
    "\n",
    "            p = np.array(channel_coords[event['Channel']])\n",
    "            d = np.linalg.norm(np.cross(p-a, p-b)) / np.linalg.norm(b-a)\n",
    "\n",
    "            dlist.append(d)\n",
    "\n",
    "        # get root mean squared error for cluster\n",
    "        RMSE = math.sqrt(sum([i**2 for i in dlist])/(2* len(dlist) - 4))\n",
    "\n",
    "        # normalize\n",
    "        NRMSE = RMSE / 4.54**2\n",
    "\n",
    "        return NRMSE\n",
    "    \n",
    "\n",
    "    def lineplanecollision(self, planeNormal, planePoint, rayDirection, rayPoint, epsilon=1e-6):\n",
    "\n",
    "        ndotu = planeNormal.dot(rayDirection)\n",
    "        if abs(ndotu) < epsilon:\n",
    "            return None\n",
    "\n",
    "        t = -planeNormal.dot(rayPoint - planePoint) / ndotu\n",
    "\n",
    "        return rayPoint + t * rayDirection\n",
    "\n",
    "    \n",
    "    def linecubecollision(self, cubeCenter, cubeLength, rayDirection, rayPoint, epsilon=1e-6):\n",
    "\n",
    "        cubeCollisions = []\n",
    "\n",
    "\n",
    "        halfLength = cubeLength / 2.0\n",
    "\n",
    "        directions = np.array([\n",
    "            [0,0,halfLength], #up\n",
    "            [0,halfLength,0], #front\n",
    "            [halfLength,0,0], #right\n",
    "        ])\n",
    "\n",
    "        planeCollisions = []\n",
    "        for i in range(6):\n",
    "            if i >= 3:\n",
    "                faceNormal = -directions[i%3] # to get down, back, left\n",
    "            else:\n",
    "                faceNormal = directions[i]\n",
    "\n",
    "            facePoint = cubeCenter + faceNormal\n",
    "\n",
    "            collision = self.lineplanecollision(faceNormal, facePoint, rayDirection, rayPoint)\n",
    "            if collision is not None:\n",
    "                planeCollisions.append(collision)\n",
    "\n",
    "        #check if intersection is outside cube\n",
    "        for collision in planeCollisions:\n",
    "\n",
    "            inside = True\n",
    "            for i in range(3):\n",
    "                if collision[i] > (cubeCenter[i] + halfLength + epsilon) or collision[i] < (cubeCenter[i] - halfLength - epsilon):\n",
    "                    inside = False\n",
    "\n",
    "            if inside:\n",
    "                cubeCollisions.append(collision)\n",
    "\n",
    "        return cubeCollisions\n",
    "    \n",
    "    \n",
    "    def channelcollisions(self, linepoints):\n",
    "                \n",
    "        rayDirection = linepoints[1] - linepoints[0]\n",
    "        rayPoint = linepoints[0]\n",
    "        cubeLength = 50\n",
    "        \n",
    "        coords = self.load_coords()\n",
    "    \n",
    "        hit_channels = []\n",
    "                        \n",
    "        for channel in range(1,len(coords)+1):\n",
    "            cubeCenter = np.array(coords[channel])\n",
    "\n",
    "\n",
    "            collision = self.linecubecollision(cubeCenter, cubeLength, rayDirection, rayPoint)\n",
    "            if len(collision) == 2:\n",
    "                hit_channels.append(channel)\n",
    "                                \n",
    "        return hit_channels\n",
    "    \n",
    "    \n",
    "    def errorchannels(self,cluster):\n",
    "\n",
    "        linepoints = self.fitline(cluster)\n",
    "        hitchannels = self.channelcollisions(linepoints)\n",
    "        clusterchannels = cluster['Channel'].unique()\n",
    "\n",
    "        missing = [ch for ch in hitchannels if ch not in clusterchannels]\n",
    "        extra = [ch for ch in clusterchannels if ch not in hitchannels]\n",
    "        \n",
    "        return (missing, extra)\n",
    "\n",
    "    \n",
    "    def clusterzenith(self, cluster):\n",
    "        linepoints = self.fitline(cluster)\n",
    "\n",
    "        z = abs(linepoints[0][2] - linepoints[1][2])\n",
    "        d = abs(np.linalg.norm(linepoints[0] - linepoints[1]))\n",
    "        return math.acos(z/d)\n",
    "    \n",
    "    def clusterazimuth(self, cluster):\n",
    "        linepoints = self.fitline(cluster)\n",
    "\n",
    "        y = linepoints[0][1] - linepoints[1][1]\n",
    "        x = linepoints[0][0] - linepoints[1][0]\n",
    "        \n",
    "        # confine to 1st and 4th quadrant\n",
    "        if x < 0:\n",
    "            y*=-1\n",
    "            x*=-1\n",
    "        \n",
    "        return math.atan2(y, x)\n",
    "        \n",
    "        if(x == 0):\n",
    "            return math.pi/2\n",
    "        else:\n",
    "            return math.atan(y/x)\n",
    "            print(y)\n",
    "            print(x)\n",
    "\n",
    "    \n",
    "    def make_clusterDF(self):\n",
    "        # get clusters\n",
    "        clusters = np.unique(self.eventdf['Cluster'])\n",
    "        numofclusters = len(clusters)\n",
    "\n",
    "        eventspercluster = []\n",
    "        channelspercluster = []    \n",
    "        starttimes = []\n",
    "        timespreads = []\n",
    "        NRMSE = []\n",
    "        extrachannels = []\n",
    "        missingchannels = []\n",
    "        zeniths = []\n",
    "        azimuths = []\n",
    "\n",
    "        collision_time = 0\n",
    "\n",
    "        for c in range(numofclusters):\n",
    "\n",
    "            cluster = self.eventdf[self.eventdf['Cluster'] == c]\n",
    "\n",
    "            #event and channel info\n",
    "            eventspercluster.append(len(cluster))\n",
    "            channelspercluster.append(len(cluster['Channel'].unique()))\n",
    "\n",
    "            #get timespread\n",
    "            clustertimes = cluster['MaxTime']\n",
    "            starttimes.append(min(clustertimes))\n",
    "            timespreads.append(max(clustertimes) - min(clustertimes))\n",
    "\n",
    "            #get NRMSE\n",
    "            NRMSE.append(self.clusterNRMSE(cluster))\n",
    "            \n",
    "            start = time.time()\n",
    "            \n",
    "            #get missing and extra channels\n",
    "            missing, extra = self.errorchannels(cluster)\n",
    "            \n",
    "            extrachannels.append(len(extra))\n",
    "            missingchannels.append(len(missing))\n",
    "            \n",
    "            collision_time += (time.time() - start)\n",
    "\n",
    "            #get angles\n",
    "            zeniths.append(self.clusterzenith(cluster))\n",
    "            azimuths.append(self.clusterazimuth(cluster))\n",
    "        \n",
    "        print(collision_time)\n",
    "\n",
    "        #zeniths_degrees = [theta*360/(2*math.pi) for theta in zeniths]\n",
    "        #cos_theta = [math.cos(theta) for theta in zeniths]\n",
    "\n",
    "        d = {'Cluster' : clusters, 'Events' : eventspercluster, 'Channels' : channelspercluster, \\\n",
    "            'StartTime': starttimes, 'TimeSpread' : timespreads, 'NRMSE' : NRMSE, \\\n",
    "             'Zenith' : zeniths,'Azimuth': azimuths, 'ExtraCh': extrachannels, 'MissingCh' : missingchannels}\n",
    "\n",
    "        newdf = pd.DataFrame(data=d)\n",
    "\n",
    "        #return newdf\n",
    "        self.clusterdf = newdf\n",
    "        \n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def filter_clusterdf(self, NRMSE, channels):\n",
    "        self.clusterdf = self.clusterdf[self.clusterdf['NRMSE'] < NRMSE]\n",
    "        self.clusterdf = self.clusterdf[self.clusterdf['Channels'] >= channels]\n",
    "        \n",
    "        return self\n",
    "\n",
    "\n",
    "    def get_clusterdf(self):\n",
    "        return self.clusterdf\n",
    "    \n",
    "    \n",
    "    def get_clusterrate(self):\n",
    "        \n",
    "        num_clusters = len(self.clusterdf)\n",
    "\n",
    "        # fix times\n",
    "        with open(pwd + \"/data/ds3564_start_stop_times.txt\") as f:\n",
    "            f.readline()\n",
    "            f.readline()\n",
    "\n",
    "            first = True\n",
    "\n",
    "            sum = timedelta()\n",
    "\n",
    "            for line in f:\n",
    "                linedata = line.split('|')\n",
    "                linedata = [i.lstrip().rstrip() for i in linedata]\n",
    "\n",
    "                if linedata[2] == \"Background\" and linedata[6] == \"OK (0)\":\n",
    "\n",
    "                    (h, m, s) = linedata[5].split(':')\n",
    "                    d = timedelta(hours=int(h), minutes=int(m), seconds=int(s))\n",
    "                    sum += d\n",
    "\n",
    "        total_seconds = sum.total_seconds()\n",
    "\n",
    "        return float(num_clusters) / float(total_seconds)\n",
    "    \n",
    "    \n",
    "    def get_cluster(self, cluster_num):\n",
    "        return self.eventdf[self.eventdf['Cluster'] == cluster_num]\n",
    "    \n",
    "        \n",
    "    def show_cluster(self, cluster_list, x1=15, x2=45):\n",
    "        \n",
    "        plt.figure(figsize=(10,10))\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.set_proj_type('ortho')\n",
    "        \n",
    "        #if given int, make list\n",
    "        if isinstance(cluster_list, int):\n",
    "            cluster_list = [cluster_list]\n",
    "            \n",
    "        for c in cluster_list:\n",
    "            cluster = self.eventdf[self.eventdf['Cluster'] == c]\n",
    "\n",
    "            coords = self.clustercoords(cluster)\n",
    "            ax.scatter3D(*coords)\n",
    "\n",
    "            line = self.fitline(cluster)\n",
    "            ax.plot3D(*line.T)\n",
    "\n",
    "        plt.xlim([-350,350])\n",
    "        plt.ylim([-350,350])\n",
    "        ax.set_zlim([-350,350])\n",
    "\n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('y')\n",
    "        ax.set_zlabel('z')\n",
    "\n",
    "        ax.view_init(x1, x2)\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    def show_simulated(self, cluster_num, x1=15, x2=45):\n",
    "\n",
    "        linepoints = self.fitline(self.get_cluster(cluster_num))\n",
    "        hit_channels = self.channelcollisions(linepoints)\n",
    "        coords = self.load_coords()\n",
    "\n",
    "        hit_channel_coords = np.array([coords[channel] for channel in hit_channels])\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.set_proj_type('ortho')\n",
    "\n",
    "        ax.scatter3D(*hit_channel_coords.T)\n",
    "        ax.plot3D(*linepoints.T)\n",
    "\n",
    "        plt.xlim([-350,350])\n",
    "        plt.ylim([-350,350])\n",
    "        ax.set_zlim([-350,350])\n",
    "\n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('y')\n",
    "        ax.set_zlabel('z')\n",
    "\n",
    "        ax.view_init(x1, x2)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
