{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import uproot as up\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from scipy import stats\n",
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "import time\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#from pymoo.algorithms.unsga3 import UNSGA3\n",
    "#from pymoo.algorithms.nsga2 import NSGA2\n",
    "from pymoo.factory import get_sampling, get_crossover, get_mutation\n",
    "from pymoo.factory import get_termination\n",
    "from pymoo.optimize import minimize\n",
    "\n",
    "\n",
    "from pymoo.algorithms.nsga3 import NSGA3\n",
    "from pymoo.factory import get_problem, get_reference_directions\n",
    "\n",
    "%run new_MyProblem.ipynb\n",
    "\n",
    "        \n",
    "class testDataAnalysis():\n",
    "    def __init__(self, auto=False, load=False, eventfile='', clusterfile=''): \n",
    "        \n",
    "        self.pwd = \".\"\n",
    "        #self.pwd = str(Path().absolute())\n",
    "        #self.pwd = \"/nfs/cuore1/scratch/yocum\"\n",
    "        self.coords = self.load_coords()\n",
    "        \n",
    "        self.noisy = []\n",
    "        self.dead = []\n",
    "        \n",
    "        if load:\n",
    "            self.load_eventdf(eventfile)\n",
    "            self.load_clusterdf(clusterfile)\n",
    "            \n",
    "        elif auto:\n",
    "            #self.eventdf = self.load_data()\n",
    "            self.load_data()\n",
    "            self.load_errorchannels(self)\n",
    "            #self.filter_baseline()\n",
    "            self.arrange_clusters(5, 1.0) # >= 5 events, <= 1.0 seconds\n",
    "            self.make_clusterdf(basicfit=True)\n",
    "            self.filter_fit(3.5, 5) # <= 1.5 NRMSE, >= 0 channels\n",
    "    \n",
    "    def get_eventdf(self):\n",
    "        return copy.deepcopy(self.eventdf)\n",
    "    \n",
    "    def set_eventdf(self, df):\n",
    "        self.eventdf = df\n",
    "        \n",
    "    def set_clusterdf(self, df):\n",
    "        self.clusterdf = df\n",
    "        \n",
    "    def load_eventdf(self, file):\n",
    "        self.eventdf = pd.read_csv(file)\n",
    "        self.eventdf = self.eventdf.sort_values(by=['MaxTime'])\n",
    "        self.eventdf = self.eventdf.reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "    def load_clusterdf(self, file):\n",
    "        self.clusterdf = pd.read_csv(file, low_memory=True, sep=',')\n",
    "        self.clusterdf = self.clusterdf.sort_values(by=['Cluster'])\n",
    "        self.clusterdf = self.clusterdf.reset_index(drop=True)\n",
    "        self.clusterdf['Fitline'] = self.clusterdf['Fitline'].apply(\n",
    "            lambda rawline: np.array(rawline.strip('[]').split() if isinstance(rawline, str) else rawline, dtype=np.float64)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def load_errorchannels(self):\n",
    "        self.dead = np.genfromtxt(self.pwd + '/data/errorchannels/dead_channels.csv', delimiter=',')\n",
    "        self.noisy = np.genfromtxt(self.pwd + '/data/errorchannels/noisy_channels.csv', delimiter=',')\n",
    "        \n",
    "        self.dead.astype(int)\n",
    "        self.noisy.astype(int)\n",
    "        \n",
    "    \n",
    "    def save_eventdf(self, path):\n",
    "        self.eventdf.to_csv(path, index=False)\n",
    "    \n",
    "    def save_clusterdf(self, path):\n",
    "        self.clusterdf.to_csv(path, index=False)\n",
    "        \n",
    "        \n",
    "    def save_errorchannels(self):\n",
    "        with open(self.pwd + \"/data/errorchannels/dead_channels.csv\", \"a\") as f:\n",
    "            np.savetxt(f, self.dead, delimiter=\",\")\n",
    "            \n",
    "        with open(self.pwd + \"/data/errorchannels/noisy_channels.csv\", \"a\") as f:\n",
    "            np.savetxt(f, self.noisy, delimiter=\",\")\n",
    "        \n",
    "    \n",
    "    def load_data(self):\n",
    "        frames = []\n",
    "        path = self.pwd + '/data/ds3564/'\n",
    "        \n",
    "        #num_towers = len(os.listdir(path))\n",
    "        num_towers = 19\n",
    "        filename = 'ds3564Tower'\n",
    "\n",
    "        for t in range(1, num_towers + 1):\n",
    "            new_path = path + filename + str(t) + '.root'\n",
    "\n",
    "            #load tower\n",
    "            event = up.open(new_path)['tree']\n",
    "\n",
    "            #recast the data as a pandas dataframe and append to frames\n",
    "            frames.append(event.pandas.df())\n",
    "\n",
    "        raw = pd.concat(frames)\n",
    "        \n",
    "        #adjust variable from milli to seconds\n",
    "        raw['MaxPosInWindow'] = raw['MaxPosInWindow'] / 1000.0\n",
    "        \n",
    "        #set saturated flag\n",
    "        raw['IsSaturated'] = np.logical_or((raw['Baseline'] + raw['MaxToBaseline']) > 9000, raw['SelectedEnergy'] > 25000)\n",
    "        \n",
    "        run_starttimes = self.runstarttimes()\n",
    "        \n",
    "        for run in raw['Run'].unique():\n",
    "            raw.loc[raw['Run'] == run, ['Time']] += run_starttimes[run]\n",
    "        \n",
    "        self.eventdf = raw\n",
    "        #return raw\n",
    "\n",
    "    \n",
    "    def runstarttimes(self):\n",
    "\n",
    "        times = {}\n",
    "\n",
    "        # fix times\n",
    "        with open(self.pwd + \"/data/ds3564_start_stop_times.txt\") as f:\n",
    "            f.readline()\n",
    "            f.readline()\n",
    "\n",
    "            first = True\n",
    "\n",
    "            for line in f:\n",
    "                linedata = line.split('|')\n",
    "                linedata = [i.lstrip().rstrip() for i in linedata]\n",
    "\n",
    "                if linedata[2] == \"Background\" and linedata[6] == \"OK (0)\":\n",
    "\n",
    "                    linedate = datetime.strptime(linedata[3], \"%b %d, %Y %H:%M:%S%z\")\n",
    "                    #print(linedate.timestamp())\n",
    "                    timestamp = linedate.replace(tzinfo=timezone.utc).timestamp()\n",
    "\n",
    "                    # save first run timestamp\n",
    "                    if first:\n",
    "                        first_timestamp = timestamp\n",
    "                        first = False\n",
    "\n",
    "                    times[int(linedata[1])] = timestamp - first_timestamp\n",
    "        return times\n",
    "    \n",
    "    \n",
    "    def eventsperchannel(self):\n",
    "        # get num events per channel\n",
    "        events = []\n",
    "        for c in range(1,max(self.eventdf['Channel']) + 1):\n",
    "            events.append(len(self.eventdf[self.eventdf['Channel'] == c]))\n",
    "        return events\n",
    "    \n",
    "    \n",
    "    # find dead channels\n",
    "    def deadchannels(self):\n",
    "        if len(self.dead) == 0:\n",
    "            channel_events = self.eventsperchannel()\n",
    "\n",
    "            dead = []\n",
    "            for c in range(1,max(self.eventdf['Channel']) + 1):     \n",
    "                if channel_events[c - 1] == 0:\n",
    "                    dead.append(c)\n",
    "            self.dead = dead\n",
    "            \n",
    "        return self.dead\n",
    "        \n",
    "    \n",
    "    \n",
    "    #detect outliers using above threshold IQR\n",
    "    def noisychannels(self):\n",
    "        if len(self.noisy) == 0:\n",
    "            threshold = 1.5\n",
    "\n",
    "            channel_events = self.eventsperchannel()        \n",
    "            Q1, Q3 = np.percentile(channel_events, 25), np.percentile(channel_events, 75)\n",
    "            IQR = Q3 - Q1\n",
    "\n",
    "            upper_bound = Q3 + IQR * threshold\n",
    "            noisy = [c for c in range(1,max(self.eventdf['Channel']) + 1) if channel_events[c - 1] > upper_bound]\n",
    "            self.noisy = noisy\n",
    "        \n",
    "        return noisy\n",
    "\n",
    "    \n",
    "    def filter_noisy(self):\n",
    "        self.eventdf = self.eventdf[np.isin(self.eventdf['Channel'], self.noisychannels(), invert=True)]\n",
    "        \n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def filter_baseline(self):\n",
    "        self.eventdf = self.eventdf[(self.eventdf['Baseline'] + self.eventdf['MaxToBaseline']) < 9000]\n",
    "        self.eventdf = self.eventdf[(self.eventdf['SelectedEnergy']) < 25000]\n",
    "\n",
    "        return self\n",
    "        \n",
    "    \n",
    "    def arrange_clusters(self, e_thresh=3, t_thresh=1.0):\n",
    "        \n",
    "        e_thresh = int(e_thresh)\n",
    "        t_thresh = float(t_thresh)\n",
    "        \n",
    "        sorted_df = self.eventdf.copy()\n",
    "        \n",
    "        sorted_df['MaxTime'] =  self.eventdf[['Time', 'MaxPosInWindow']].sum(axis=1) # sort by 'Time' + 'MaxPosInWindow'\n",
    "        #sorted_df['MaxTime'] =  self.eventdf[['Time', 'OFdelay']].sum(axis=1) # sort by 'Time' + 'MaxPosInWindow'\n",
    "        #sorted_df['MaxTime'] = self.eventdf['Time'] # Sort by 'Time'\n",
    "        \n",
    "        \n",
    "        sorted_df = sorted_df.sort_values(by=['MaxTime'])\n",
    "        sorted_df = sorted_df.reset_index(drop=True)\n",
    "\n",
    "        new_df = sorted_df.copy()\n",
    "\n",
    "        #print(new_df[50:70])\n",
    "\n",
    "        new_df['Cluster'] = [-1]*len(new_df)\n",
    "\n",
    "        #get events that are clustered\n",
    "        row = 0\n",
    "        events = 1\n",
    "        cluster = [row]\n",
    "        cluster_num = 0\n",
    "\n",
    "        while (row < len(self.eventdf)):\n",
    "\n",
    "            #make sure there is a next event. if at end of dataframe, set times to fail next test\n",
    "            if(row < len(self.eventdf) - 1):\n",
    "                successive_time = sorted_df.iloc[row + 1]['MaxTime'] #+ sorted_df.iloc[row + 1]['MaxPosInWindow']/1000.0\n",
    "                event_time = sorted_df.iloc[row]['MaxTime'] #+ sorted_df.iloc[row]['MaxPosInWindow']/1000.0\n",
    "            else:\n",
    "                event_time = 0\n",
    "                successive_time = t_thresh + 1\n",
    "\n",
    "\n",
    "            if abs(successive_time - event_time) <= t_thresh:\n",
    "                events += 1\n",
    "                cluster.append(row + 1)\n",
    "            else:   \n",
    "\n",
    "                #print(events)\n",
    "                if events < e_thresh:\n",
    "                    for i in cluster:\n",
    "                        new_df = new_df.drop(i) #sorted_df.index[i])\n",
    "                else:\n",
    "                    #clusters.append(cluster)\n",
    "                    for i in cluster:\n",
    "                        #print(cluster_num)\n",
    "                        new_df.loc[i, 'Cluster'] = cluster_num\n",
    "                    cluster_num += 1\n",
    "\n",
    "                events = 1\n",
    "                cluster = [row + 1]\n",
    "\n",
    "            row += 1\n",
    "        \n",
    "        self.eventdf = new_df\n",
    "    \n",
    "        return self\n",
    "\n",
    "\n",
    "    # create dictionary mapping channel numbers to a tuple containing coordinates (x,y,z)\n",
    "    def load_coords(self):\n",
    "\n",
    "        coords = {}\n",
    "\n",
    "        with open(self.pwd + \"/data/detector_positions.txt\", 'r') as f:\n",
    "            for line in f:\n",
    "                data = line.split(',')\n",
    "\n",
    "                if int(data[0]) < 1000:\n",
    "                    coords[int(data[0])] = (float(data[1]), float(data[2]), float(data[3]))\n",
    "\n",
    "        return coords\n",
    "\n",
    "    # returns array of 3 arrays corresponding to x y z\n",
    "    def clustercoords(self, cluster):\n",
    "\n",
    "        #coords = []\n",
    "        x = []\n",
    "        y = []\n",
    "        z = []\n",
    "\n",
    "        for c in cluster['Channel']:\n",
    "            #coords.append([ch_coords[c][0], ch_coords[c][1], ch_coords[c][2]])\n",
    "            x.append(self.coords[c][0])\n",
    "            y.append(self.coords[c][1])\n",
    "            z.append(self.coords[c][2])\n",
    "\n",
    "        return [x,y,z]\n",
    "    \n",
    "    \n",
    "    def pts_to_line(self, line_pts):\n",
    "        \n",
    "        p = np.array(line_pts)[:3]\n",
    "        a = np.array(line_pts)[3:]\n",
    "        \n",
    "        v = (a - p) / np.linalg.norm(a - p)\n",
    "        \n",
    "        x = np.array([p, v]).flatten()\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def line_to_pts(self, line):\n",
    "        x = np.array(line)\n",
    "        \n",
    "        p = x[:3]\n",
    "        v = x[3:]\n",
    "        return v * np.mgrid[-800:800:2j][:, np.newaxis] + p\n",
    "\n",
    "    \n",
    "    # takes dataframe of a single cluster and finds line of best fit\n",
    "    def basicfit(self, cluster):\n",
    "        coords = self.clustercoords(cluster)\n",
    "\n",
    "        data  = np.array(coords).T\n",
    "\n",
    "        datamean = data.mean(axis=0)\n",
    "\n",
    "        # Do an SVD on the mean-centered data.\n",
    "        uu, dd, vv = np.linalg.svd(data - datamean)\n",
    "\n",
    "        #linepts = vv[0] * np.mgrid[-400:400:2j][:, np.newaxis]\n",
    "\n",
    "        # shift by the mean to get the line in the right place\n",
    "        #linepts += datamean\n",
    "        \n",
    "        v = vv[0] / np.linalg.norm(vv[0])\n",
    "        p = datamean\n",
    "\n",
    "        #return linepts\n",
    "        return np.round(np.append(p, v), decimals=6)\n",
    "\n",
    "    \n",
    "    \n",
    "    # takes dataframe of a single cluster and finds line of best fit\n",
    "    def fitline(self, cluster, pop_num=50, gen_num=200, verbose=False):\n",
    "        \n",
    "        hit_chs = cluster['Channel'].values\n",
    "        hit_chs = hit_chs[np.isin(hit_chs, self.noisy, invert=True)]\n",
    "\n",
    "        non_sat_chs = cluster[cluster['IsSaturated'] == False]['Channel'].values\n",
    "        non_sat_chs = non_sat_chs[np.isin(non_sat_chs, self.noisy, invert=True)]\n",
    "        \n",
    "        if len(hit_chs) < 3:\n",
    "            return self.basicfit(cluster)\n",
    "        \n",
    "        miss_chs = np.array([ch for ch in range(1,989) if ch not in hit_chs])\n",
    "        miss_chs[np.isin(miss_chs, self.dead, invert=True)]\n",
    "        \n",
    "        ref_dirs = get_reference_directions(\"das-dennis\", 3, n_partitions=200)\n",
    "        \n",
    "        algorithm = NSGA3(\n",
    "            pop_size=pop_num,\n",
    "            ref_dirs=ref_dirs,\n",
    "            #n_offsprings=pop_num,\n",
    "            sampling=get_sampling(\"real_random\"),\n",
    "            crossover=get_crossover(\"real_sbx\", prob=1.0, eta=15),\n",
    "            mutation=get_mutation(\"real_pm\", eta=20),\n",
    "            eliminate_duplicates=True\n",
    "        )\n",
    "        \n",
    "        termination = get_termination(\"n_gen\", gen_num)\n",
    "        \n",
    "        problem = testMyProblem(hit_chs, miss_chs, non_sat_chs, cluster['StabAmp'].values)\n",
    "        #problem = MyProblem()\n",
    "        \n",
    "        res = minimize(problem,\n",
    "                       algorithm,\n",
    "                       termination,\n",
    "                       #seed=1\n",
    "                       #pf=problem.pareto_front(use_cache=False),\n",
    "                       #save_history=True)\n",
    "                       verbose=verbose\n",
    "                      )\n",
    "        if verbose:\n",
    "            print(res.X)\n",
    "            print(res.F)\n",
    "            \n",
    "        f = 0 * res.F[:,0] + 0 * res.F[:,1] + res.F[:,2] # possibly add weights here?\n",
    "        sorted_f = sorted(f)\n",
    "        \n",
    "        bestline = []\n",
    "        #bestscore = np.inf\n",
    "        \n",
    "        best_missed = np.inf\n",
    "        best_extra = np.inf\n",
    "        best_linear = np.inf\n",
    "        \n",
    "        bestline = res.X[np.where(f==sorted_f[0])[0][0]]\n",
    "                \n",
    "        \n",
    "        \n",
    "       #if sorted_f[0] != 1.0:\n",
    "       #     bestline = res.X[np.where(f==sorted_f[0])[0][0]] != 1.0\n",
    "       # \n",
    "        #else:\n",
    "            \n",
    "\n",
    "        #find best line out of top ten\n",
    "        for i in range(len(res.X)):\n",
    "        #for betterline in res.X:\n",
    "\n",
    "            index = np.where(f==sorted_f[i])[0][0]\n",
    "\n",
    "            betterline = self.pts_to_line(res.X[index])\n",
    "            hit_channels = self.channelcollisions(betterline)[0]\n",
    "            missed, extra = self.errorchannels(cluster, hit_channels)\n",
    "            linear = res.F[index][2]\n",
    "\n",
    "            if verbose and len(missed) == 0 and len(extra) == 0:\n",
    "                print(betterline, res.F[index])\n",
    "\n",
    "\n",
    "            if len(missed) < best_missed:\n",
    "                best_missed = len(missed)\n",
    "                best_extra = len(extra)\n",
    "                best_linear = linear\n",
    "                bestline = betterline\n",
    "\n",
    "            elif (len(missed) == best_missed) and (len(extra) < best_extra):\n",
    "                best_extra = len(extra)\n",
    "                best_linear = linear\n",
    "                bestline = betterline\n",
    "                \n",
    "            elif (len(missed) == best_missed) and (len(extra) == best_extra) and (linear < best_linear):\n",
    "                best_linear = linear\n",
    "                bestline = betterline\n",
    "\n",
    "\n",
    "            #if best_missed + best_extra == 0:\n",
    "            #    bestline[3:] = bestline[3:] / np.linalg.norm(bestline[3:])\n",
    "            #    return bestline\n",
    "\n",
    "\n",
    "                \n",
    "            #print((best_missed, best_extra))\n",
    "\n",
    "            #if len(extra) + len(missed) < bestscore:\n",
    "            #    bestline = betterline\n",
    "            #    bestscore = len(extra) + len(missed)\n",
    "            #    print(bestscore)\n",
    "            \n",
    "        '''\n",
    "                \n",
    "        #normalize direction vector\n",
    "        bestline[3:] = bestline[3:] / np.linalg.norm(bestline[3:])\n",
    "        \n",
    "        # at end of analysis, check if we are any better off than how we started\n",
    "        basicline = self.basicfit(cluster)\n",
    "        hit_channels = self.channelcollisions(basicline)[0]\n",
    "        basic_missed, basic_extra = self.errorchannels(cluster, hit_channels)\n",
    "        \n",
    "        # also maybe consider flagging the fact that we used basicfit line?\n",
    "        #if len(basic_extra) + len(basic_missed) < bestscore:\n",
    "        #        print(\"NSGA2 failure...defaulting to LSR\")\n",
    "        #        bestscore = len(basic_extra) + len(basic_missed)\n",
    "        \n",
    "        \n",
    "        if len(basic_missed) < best_missed:\n",
    "            print(\"NSGA2 failure...defaulting to LSR\")\n",
    "            best_missed = len(basic_missed)\n",
    "            best_extra = len(basic_extra)\n",
    "            bestline = basicline\n",
    "\n",
    "        elif len(basic_missed) == best_missed and len(basic_extra) < best_extra:\n",
    "            print(\"NSGA2 failure...defaulting to LSR\")\n",
    "            best_extra = len(basic_extra)\n",
    "            bestline = basicline\n",
    "        \n",
    "        '''\n",
    "    \n",
    "        return np.round(bestline, decimals=6)\n",
    "    \n",
    "        \n",
    "    def dEdx(self, cluster, line, show_graph=False):\n",
    "\n",
    "        hit_channels, _, track_distances = self.channelcollisions(line)\n",
    "        \n",
    "        non_sat_chs = []\n",
    "        energies = []\n",
    "                    \n",
    "        for i, row in cluster.iterrows():\n",
    "            if not row['IsSaturated'] and row['Channel'] not in self.noisy:\n",
    "                non_sat_chs.append(row['Channel'])\n",
    "                energies.append(row['SelectedEnergy'])\n",
    "        \n",
    "        non_sat_chs = np.array(non_sat_chs)\n",
    "        \n",
    "        #print(line)\n",
    "        #print(hit_channels)\n",
    "        #print(self.hit_chs)\n",
    "        \n",
    "        print(non_sat_chs)\n",
    "        print(energies)\n",
    "\n",
    "        data = []\n",
    "        for i in range(len(non_sat_chs)):\n",
    "            if non_sat_chs[i] in hit_channels:\n",
    "                data.append((track_distances[np.where(hit_channels == non_sat_chs[i])[0][0]], energies[i]))\n",
    "            #else:\n",
    "            #    data = []\n",
    "            #    break   \n",
    "\n",
    "        data = np.array(data)\n",
    "        modifier = len(non_sat_chs) - len(data) + 1\n",
    "\n",
    "        #print(hit_channels)\n",
    "        #print(self.hit_chs)\n",
    "\n",
    "        if len(data) in [0,1,2]:\n",
    "            m, r2 = (1.0, 0.0)\n",
    "        \n",
    "        else:\n",
    "            x = data[:,0][:,np.newaxis]            \n",
    "            y = data[:,1]\n",
    "\n",
    "            slope, _, _, _ = np.linalg.lstsq(x, y, rcond=None)\n",
    "            m = slope[0]\n",
    "            r2 = r2_score(y, data[:,0] * m)\n",
    "            \n",
    "        \n",
    "        if show_graph:\n",
    "            plt.scatter(data[:,0], data[:,1])\n",
    "            plt.plot(np.linspace(0,70), np.linspace(0,70)*m, label='r2='+str(r2))\n",
    "            \n",
    "            plt.ylabel(\"Selected Energy (keV)\")\n",
    "            plt.xlabel(\"Path length (mm)\")\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.show()\n",
    "        \n",
    "        \n",
    "        return (m, r2)\n",
    "\n",
    "    #return stats.linregress(data[:,0], data[:,1])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def NRMSE(self, cluster, line):\n",
    "        ''' gets NRMSE for a given cluster\n",
    "            use distance from point to line of best fit as residual where\n",
    "            d = |(p-a)x(p-b)|/|b-a|\n",
    "            and variables are vectors'''\n",
    "        \n",
    "        if len(cluster) <= 2:\n",
    "            return 0\n",
    "\n",
    "        dlist = []\n",
    "        \n",
    "        # store 2 best fit lines as vectors\n",
    "        linepoints = self.line_to_pts(line)\n",
    "        a = linepoints[0]\n",
    "        b = linepoints[1]\n",
    "\n",
    "        for index, event in cluster.iterrows():\n",
    "\n",
    "            p = np.array(self.coords[event['Channel']])\n",
    "            d = np.linalg.norm(cross(p-a, p-b)) / np.linalg.norm(b-a)\n",
    "\n",
    "            dlist.append(d)\n",
    "\n",
    "        # get root mean squared error for cluster\n",
    "        RMSE = math.sqrt(sum([i**2 for i in dlist])/(2* len(dlist) - 4))\n",
    "\n",
    "        # normalize\n",
    "        NRMSE = RMSE / 4.54**2\n",
    "\n",
    "        return NRMSE\n",
    "     \n",
    "    def errorchannels(self,cluster, hitchannels):\n",
    "        \n",
    "        #hitchannels = self.channelcollisions(line)[0]\n",
    "        clusterchannels = cluster['Channel'].unique()\n",
    "        \n",
    "        if -1 not in clusterchannels:\n",
    "        \n",
    "            extra = [ch for ch in hitchannels if ch not in clusterchannels]\n",
    "            missing = [ch for ch in clusterchannels if ch not in hitchannels]\n",
    "\n",
    "            return (missing, extra)\n",
    "        \n",
    "        else:\n",
    "            return ([], [])\n",
    "        \n",
    "        \n",
    "    def zenith(self, line):\n",
    "        \n",
    "        linepoints = self.line_to_pts(line)\n",
    "\n",
    "        z = abs(linepoints[0][2] - linepoints[1][2])\n",
    "        d = abs(np.linalg.norm(linepoints[0] - linepoints[1]))\n",
    "        return math.acos(z/d)\n",
    "    \n",
    "    \n",
    "    def azimuth(self, line):\n",
    "        \n",
    "        linepoints = self.line_to_pts(line)\n",
    "\n",
    "        y = linepoints[0][1] - linepoints[1][1]\n",
    "        x = linepoints[0][0] - linepoints[1][0]\n",
    "        \n",
    "        # confine to 1st and 4th quadrant\n",
    "        if x < 0:\n",
    "            y*=-1\n",
    "            x*=-1\n",
    "        \n",
    "        az = math.atan2(y,x)\n",
    "        az -= 36.24 * np.pi / 180\n",
    "        \n",
    "        if az <= -np.pi/2:\n",
    "            az += np.pi\n",
    "        \n",
    "        return az\n",
    "    \n",
    "    \n",
    "        \n",
    "    def lineplanecollision(self, planeNormal, planePoint, rayDirection, rayPoint, epsilon=1e-6):\n",
    "\n",
    "        ndotu = planeNormal.dot(rayDirection)\n",
    "        if abs(ndotu) < epsilon:\n",
    "            return None\n",
    "\n",
    "        t = -planeNormal.dot(rayPoint - planePoint) / ndotu\n",
    "\n",
    "        return rayPoint + t * rayDirection\n",
    "\n",
    "    \n",
    "    def linecubecollision(self, cubeCenter, cubeLength, rayDirection, rayPoint, epsilon=1e-6):\n",
    "\n",
    "        cubeCollisions = []\n",
    "\n",
    "        halfLength = cubeLength / 2.0\n",
    "\n",
    "        directions = np.array([\n",
    "            [0,0,halfLength], #up\n",
    "            [0,halfLength,0], #front\n",
    "            [halfLength,0,0], #right\n",
    "        ])\n",
    "\n",
    "        planeCollisions = []\n",
    "        for i in range(6):\n",
    "            if i >= 3:\n",
    "                faceNormal = -directions[i%3] # to get down, back, left\n",
    "            else:\n",
    "                faceNormal = directions[i]\n",
    "\n",
    "            facePoint = cubeCenter + faceNormal\n",
    "\n",
    "            collision = self.lineplanecollision(faceNormal, facePoint, rayDirection, rayPoint)\n",
    "            if collision is not None:\n",
    "                planeCollisions.append(collision)\n",
    "\n",
    "        #check if intersection is outside cube\n",
    "        for collision in planeCollisions:\n",
    "\n",
    "            inside = True\n",
    "            for i in range(3):\n",
    "                if collision[i] > (cubeCenter[i] + halfLength + epsilon) or collision[i] < (cubeCenter[i] - halfLength - epsilon):\n",
    "                    inside = False\n",
    "\n",
    "            if inside:\n",
    "                cubeCollisions.append(collision)\n",
    "\n",
    "        return cubeCollisions\n",
    "    \n",
    "    \n",
    "    def channelcollisions(self, line, epsilon=1e-6):\n",
    "        \n",
    "        rayDirection = line[3:]\n",
    "        rayPoint = line[:3]\n",
    "        \n",
    "        #rayDirection = linepoints[1] - linepoints[0]\n",
    "        #rayPoint = linepoints[0]\n",
    "        cubeLength = 50\n",
    "                \n",
    "        #start = time.time()\n",
    "        \n",
    "        hit_channels = []\n",
    "        miss_channels = []\n",
    "        track_distances = []\n",
    "        \n",
    "        for channel in range(1,len(self.coords)+1):\n",
    "            cubeCenter = self.coords[channel]\n",
    "\n",
    "            #check if cubeCenter is within range of line\n",
    "            CP = cubeCenter - rayPoint\n",
    "            distance_to_line = np.abs(np.linalg.norm(cross(CP,rayDirection)) / np.linalg.norm(rayDirection))\n",
    "\n",
    "            #print(distance_to_line)\n",
    "\n",
    "            if distance_to_line < cubeLength/2*np.sqrt(3) + epsilon:\n",
    "            #if distance_to_line < cubeLength*np.sqrt(3) + epsilon:\n",
    "\n",
    "                collision = self.linecubecollision(cubeCenter, cubeLength, rayDirection, rayPoint)\n",
    "                if len(collision) == 2:\n",
    "                    hit_channels.append(channel)\n",
    "                    track_distances.append(np.linalg.norm(collision[1] - collision[0]))\n",
    "                else:\n",
    "                    miss_channels.append(channel)\n",
    "                    \n",
    "        return (hit_channels, miss_channels, track_distances)\n",
    "       \n",
    "    \n",
    "    def make_clusterdf(self, pop_num=None, gen_num=None, basicfit = False, verbose=False):\n",
    "        # get clusters\n",
    "        clusters = np.unique(self.eventdf['Cluster'])\n",
    "        \n",
    "        eventspercluster = []\n",
    "        channelspercluster = []    \n",
    "        starttimes = []\n",
    "        timespreads = []\n",
    "        fitlines = []\n",
    "        NRMSE = []\n",
    "        extrachannels = []\n",
    "        missingchannels = []\n",
    "        zeniths = []\n",
    "        azimuths = []\n",
    "        dEdxs = []\n",
    "        dEdx_errs = []\n",
    "        \n",
    "        #add columns to eventdf\n",
    "        \n",
    "        self.eventdf['Hit'] = False\n",
    "        self.eventdf['PathLength'] = np.nan\n",
    "        \n",
    "        for c in clusters:\n",
    "\n",
    "            cluster = self.eventdf[self.eventdf['Cluster'] == c]\n",
    "\n",
    "            #event and channel info\n",
    "            if len(cluster) == 1 and cluster['Channel'].values[0] == -1:\n",
    "                eventspercluster.append(0)\n",
    "                channelspercluster.append(0)\n",
    "            else:\n",
    "                eventspercluster.append(len(cluster))\n",
    "                channelspercluster.append(len(cluster['Channel'].unique()))\n",
    "\n",
    "            #get timespread\n",
    "            clustertimes = cluster['MaxTime']\n",
    "            starttimes.append(min(clustertimes))\n",
    "            timespreads.append(max(clustertimes) - min(clustertimes))\n",
    "\n",
    "            #get fitline\n",
    "            if basicfit:\n",
    "                fitline = self.basicfit(cluster)\n",
    "            elif pop_num and gen_num:\n",
    "                fitline = self.fitline(cluster, pop_num, gen_num, verbose)\n",
    "            elif not pop_num and not gen_num:\n",
    "                fitline = self.fitline(cluster)\n",
    "            else:\n",
    "                print(\"Error: fitline unspecficied\")\n",
    "                sys.exit()\n",
    "                \n",
    "            fitlines.append(fitline)\n",
    "            \n",
    "            #get NRMSE\n",
    "            NRMSE.append(self.NRMSE(cluster, fitline))\n",
    "                        \n",
    "            #get missing and extra channels\n",
    "            hit_channels, _, track_distances = self.channelcollisions(fitline)\n",
    "            missing, extra = self.errorchannels(cluster, hit_channels)\n",
    "            \n",
    "            #save path length data to eventdf\n",
    "            hit_data = [ch in hit_channels for ch in cluster['Channel'].values]\n",
    "            path_data = []\n",
    "            for i in range(len(hit_data)):\n",
    "                if hit_data[i]:\n",
    "                    index = hit_channels.index(cluster['Channel'].values[i])\n",
    "                    path_data.append(track_distances[index])\n",
    "                else:\n",
    "                    path_data.append(np.nan)\n",
    "                    \n",
    "            self.eventdf.loc[self.eventdf['Cluster'] == c, \"Hit\"] = hit_data\n",
    "            self.eventdf.loc[self.eventdf['Cluster'] == c, \"PathLength\"] = path_data  \n",
    "            \n",
    "            #cluster['PathLength'] = track_distances\n",
    "            \n",
    "            extrachannels.append(len(extra))\n",
    "            missingchannels.append(len(missing))\n",
    "            \n",
    "            #get angles\n",
    "            zeniths.append(self.zenith(fitline))\n",
    "            azimuths.append(self.azimuth(fitline))\n",
    "                        \n",
    "            #get energies\n",
    "            dEdx, err = self.dEdx(cluster, fitline)\n",
    "            dEdxs.append(dEdx)\n",
    "            dEdx_errs.append(err)\n",
    "        \n",
    "        #zeniths_degrees = [theta*360/(2*math.pi) for theta in zeniths]\n",
    "        #cos_theta = [math.cos(theta) for theta in zeniths]\n",
    "\n",
    "        d = {'Cluster' : clusters, 'Events' : eventspercluster, 'Channels' : channelspercluster, \\\n",
    "            'StartTime': starttimes, 'TimeSpread' : timespreads, 'NRMSE' : NRMSE, \\\n",
    "             'Zenith' : zeniths,'Azimuth': azimuths, 'ExtraCh': extrachannels, 'MissingCh' : missingchannels, \\\n",
    "             'dEdx': dEdxs, 'dEdx_err': dEdx_errs, 'Fitline' : fitlines}\n",
    "\n",
    "        #return newdf\n",
    "        self.clusterdf = pd.DataFrame(data=d)\n",
    "        \n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def filter_fit(self, NRMSE, channels):\n",
    "        self.clusterdf = self.clusterdf[self.clusterdf['NRMSE'] < NRMSE]\n",
    "        self.clusterdf = self.clusterdf[self.clusterdf['Channels'] >= channels]\n",
    "        \n",
    "        if hasattr(self, 'eventdf'):\n",
    "            self.eventdf = self.eventdf[self.eventdf['Cluster'].isin(self.clusterdf['Cluster'].values)]\n",
    "        \n",
    "        return self\n",
    "\n",
    "\n",
    "    def get_clusterdf(self):\n",
    "        return copy.deepcopy(self.clusterdf)\n",
    "    \n",
    "    \n",
    "    def get_clusterrate(self):\n",
    "        \n",
    "        num_clusters = len(self.clusterdf)\n",
    "\n",
    "        # fix times\n",
    "        with open(self.pwd + \"/data/ds3564_start_stop_times.txt\") as f:\n",
    "            f.readline()\n",
    "            f.readline()\n",
    "\n",
    "            first = True\n",
    "\n",
    "            sum = timedelta()\n",
    "\n",
    "            for line in f:\n",
    "                linedata = line.split('|')\n",
    "                linedata = [i.lstrip().rstrip() for i in linedata]\n",
    "\n",
    "                if linedata[2] == \"Background\" and linedata[6] == \"OK (0)\":\n",
    "\n",
    "                    (h, m, s) = linedata[5].split(':')\n",
    "                    d = timedelta(hours=int(h), minutes=int(m), seconds=int(s))\n",
    "                    sum += d\n",
    "\n",
    "        total_seconds = sum.total_seconds()\n",
    "        \n",
    "        print('clusters: ' + str(num_clusters))\n",
    "        print('run time: ' + str(total_seconds))\n",
    "\n",
    "        return float(num_clusters) / float(total_seconds)\n",
    "    \n",
    "    \n",
    "    def get_cluster(self, cluster_list):\n",
    "        if isinstance(cluster_list, (int, np.int64)):\n",
    "            cluster_list = [cluster_list]\n",
    "        \n",
    "        return copy.deepcopy(self.eventdf[self.eventdf['Cluster'].isin(cluster_list)])\n",
    "    \n",
    "    \n",
    "    def get_fitline(self, cluster_num):\n",
    "            \n",
    "        return self.clusterdf[self.clusterdf['Cluster'] == cluster_num]['Fitline'].values[0]\n",
    "    \n",
    "    \n",
    "    def show_channel(self, channel_list, x1=15, x2=45):\n",
    "        plt.figure(figsize=(10,10))\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.set_proj_type('ortho')\n",
    "        \n",
    "        if isinstance(channel_list, (int, np.int64)):\n",
    "            channel_list = [channel_list]\n",
    "            \n",
    "        coords = np.array([self.coords[ch] for ch in channel_list]).T\n",
    "        ax.scatter3D(*coords)\n",
    "        \n",
    "        plt.xlim([-350,350])\n",
    "        plt.ylim([-350,350])\n",
    "        ax.set_zlim([-350,350])\n",
    "\n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('y')\n",
    "        ax.set_zlabel('z')\n",
    "\n",
    "        ax.view_init(x1, x2)\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "        \n",
    "    def show_cluster(self, cluster_list, x1=15, x2=45):\n",
    "        \n",
    "        plt.figure(figsize=(10,10))\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.set_proj_type('ortho')\n",
    "        \n",
    "        #if given int, make list\n",
    "        if isinstance(cluster_list, (int, np.int64)):\n",
    "            cluster_list = [cluster_list]\n",
    "            \n",
    "        for c in cluster_list:\n",
    "            cluster = self.eventdf[self.eventdf['Cluster'] == c]\n",
    "\n",
    "            coords = self.clustercoords(cluster)\n",
    "            \n",
    "            ax.scatter3D(*coords)\n",
    "\n",
    "            #line = self.fitline(cluster)\n",
    "            line = self.clusterdf[self.clusterdf['Cluster'] == c]['Fitline'].values[0]\n",
    "            linepts = self.line_to_pts(line)\n",
    "            \n",
    "            ax.plot3D(*linepts.T)\n",
    "\n",
    "        plt.xlim([-350,350])\n",
    "        plt.ylim([-350,350])\n",
    "        ax.set_zlim([-350,350])\n",
    "\n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('y')\n",
    "        ax.set_zlabel('z')\n",
    "\n",
    "        ax.view_init(x1, x2)\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    def show_simulation(self, cluster_num, x1=15, x2=45):\n",
    "        \n",
    "        #linepoints = self.fitline(self.get_cluster(cluster_num))\n",
    "        line = self.clusterdf[self.clusterdf['Cluster'] == cluster_num]['Fitline'].values[0]\n",
    "        linepts = self.line_to_pts(line)\n",
    "        \n",
    "        hit_channels = self.channelcollisions(line)[0]\n",
    "        hit_channel_coords = np.array([self.coords[channel] for channel in hit_channels])\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.set_proj_type('ortho')\n",
    "\n",
    "        ax.scatter3D(*hit_channel_coords.T)\n",
    "        ax.plot3D(*linepts.T)\n",
    "\n",
    "        plt.xlim([-350,350])\n",
    "        plt.ylim([-350,350])\n",
    "        ax.set_zlim([-350,350])\n",
    "\n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('y')\n",
    "        ax.set_zlabel('z')\n",
    "\n",
    "        ax.view_init(x1, x2)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "        \n",
    "# manually do crossproduct to avoid numpy overhead for small vectors\n",
    "def cross(a, b):\n",
    "    c = [a[1]*b[2] - a[2]*b[1],\n",
    "         a[2]*b[0] - a[0]*b[2],\n",
    "         a[0]*b[1] - a[1]*b[0]]\n",
    "    return c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
