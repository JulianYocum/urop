{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import uproot as up\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from scipy import stats\n",
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "pwd = \".\"\n",
    "#pwd = str(Path().absolute())\n",
    "#pwd = \"/nfs/cuore1/scratch/yocum\"\n",
    "\n",
    "\n",
    "class testDataAnalysis:\n",
    "    def __init__(self, auto=False, load=False, eventfile=None, clusterfile=None): \n",
    "        \n",
    "        self.coords = self.load_coords()\n",
    "        \n",
    "        if load:\n",
    "            self.eventdf = pd.read_csv(eventfile)\n",
    "            self.clusterdf = pd.read_csv(clusterfile)\n",
    "        \n",
    "        elif auto:\n",
    "            #self.eventdf = self.load_data()\n",
    "            self.load_data()\n",
    "            self.filter_noisy()\n",
    "            self.filter_baseline()\n",
    "            self.arrange_clusters(5, 1.0) # >= 5 events, <= 1.0 seconds\n",
    "            self.make_clusterdf()\n",
    "            self.filter_clusterdf(2.5, 0) # <= 1.5 NRMSE, >= 0 channels\n",
    "    \n",
    "    def get_eventdf(self):\n",
    "        return self.eventdf\n",
    "    \n",
    "    def set_eventdf(self, df):\n",
    "        self.eventdf = df\n",
    "        \n",
    "    \n",
    "    def save_eventdf(self, path):\n",
    "        self.clusterdf.to_csv(path, index=False)\n",
    "    \n",
    "    def save_clusterdf(self, path):\n",
    "        self.eventdf.to_csv(path, index=False)\n",
    "        \n",
    "    \n",
    "    def load_data(self):\n",
    "        frames = []\n",
    "        path = pwd + '/data/ds3564/'\n",
    "        \n",
    "        #num_towers = len(os.listdir(path))\n",
    "        num_towers = 19\n",
    "        filename = 'ds3564Tower'\n",
    "\n",
    "        for t in range(1, num_towers + 1):\n",
    "            new_path = path + filename + str(t) + '.root'\n",
    "\n",
    "            #load tower\n",
    "            event = up.open(new_path)['tree']\n",
    "\n",
    "            #recast the data as a pandas dataframe and append to frames\n",
    "            frames.append(event.pandas.df())\n",
    "\n",
    "        raw = pd.concat(frames)\n",
    "        \n",
    "        #adjust variable from milli to seconds\n",
    "        raw['MaxPosInWindow'] = raw['MaxPosInWindow'] / 1000.0\n",
    "        \n",
    "        \n",
    "        run_starttimes = self.runstarttimes()\n",
    "        \n",
    "        for run in raw['Run'].unique():\n",
    "            raw.loc[raw['Run'] == run, ['Time']] += run_starttimes[run]\n",
    "        \n",
    "        self.eventdf = raw\n",
    "        #return raw\n",
    "\n",
    "    \n",
    "    def runstarttimes(self):\n",
    "\n",
    "        times = {}\n",
    "\n",
    "        # fix times\n",
    "        with open(pwd + \"/data/ds3564_start_stop_times.txt\") as f:\n",
    "            f.readline()\n",
    "            f.readline()\n",
    "\n",
    "            first = True\n",
    "\n",
    "            for line in f:\n",
    "                linedata = line.split('|')\n",
    "                linedata = [i.lstrip().rstrip() for i in linedata]\n",
    "\n",
    "                if linedata[2] == \"Background\" and linedata[6] == \"OK (0)\":\n",
    "\n",
    "                    linedate = datetime.strptime(linedata[3], \"%b %d, %Y %H:%M:%S%z\")\n",
    "                    #print(linedate.timestamp())\n",
    "                    timestamp = linedate.replace(tzinfo=timezone.utc).timestamp()\n",
    "\n",
    "                    # save first run timestamp\n",
    "                    if first:\n",
    "                        first_timestamp = timestamp\n",
    "                        first = False\n",
    "\n",
    "                    times[int(linedata[1])] = timestamp - first_timestamp\n",
    "        return times\n",
    "    \n",
    "    \n",
    "    def eventsperchannel(self):\n",
    "        # get num events per channel\n",
    "        events = []\n",
    "        for c in range(1,max(self.eventdf['Channel']) + 1):\n",
    "            events.append(len(self.eventdf[self.eventdf['Channel'] == c]))\n",
    "        return events\n",
    "    \n",
    "    \n",
    "    # find dead channels\n",
    "    def deadchannels(self):\n",
    "        channel_events = self.eventsperchannel()\n",
    "        \n",
    "        ch = []\n",
    "        for c in range(1,max(self.eventdf['Channel']) + 1):     \n",
    "            if channel_events[c - 1] == 0:\n",
    "                ch.append(c)\n",
    "\n",
    "        #for c in range()\n",
    "        return ch\n",
    "    \n",
    "    \n",
    "    #detect outliers using above threshold IQR\n",
    "    def noisychannels(self):\n",
    "        threshold = 5 \n",
    "        \n",
    "        channel_events = self.eventsperchannel()        \n",
    "        Q1, Q3 = np.percentile(channel_events, 25), np.percentile(channel_events, 75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        upper_bound = Q3 + IQR * threshold\n",
    "        return [c for c in range(1,max(self.eventdf['Channel']) + 1) if channel_events[c - 1] > upper_bound]\n",
    "\n",
    "    \n",
    "    def filter_noisy(self):\n",
    "        self.eventdf = self.eventdf[np.isin(self.eventdf['Channel'], self.noisychannels(), invert=True)]\n",
    "        \n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def filter_baseline(self):\n",
    "        self.eventdf = self.eventdf[(self.eventdf['Baseline'] + self.eventdf['MaxToBaseline']) > 9000]\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    \n",
    "    def arrange_clusters(self, e_thresh=5.0, t_thresh=1.0):\n",
    "        \n",
    "        e_thresh = int(e_thresh)\n",
    "        t_thresh = float(t_thresh)\n",
    "        \n",
    "        sorted_df = self.eventdf.copy()\n",
    "        \n",
    "        sorted_df['MaxTime'] =  self.eventdf[['Time', 'MaxPosInWindow']].sum(axis=1) # sort by 'Time' + 'MaxPosInWindow'\n",
    "        #sorted_df['MaxTime'] =  self.eventdf[['Time', 'OFdelay']].sum(axis=1) # sort by 'Time' + 'MaxPosInWindow'\n",
    "        #sorted_df['MaxTime'] = self.eventdf['Time'] # Sort by 'Time'\n",
    "        \n",
    "        \n",
    "        sorted_df = sorted_df.sort_values(by=['MaxTime'])\n",
    "        sorted_df = sorted_df.reset_index(drop=True)\n",
    "\n",
    "        new_df = sorted_df.copy()\n",
    "\n",
    "        #print(new_df[50:70])\n",
    "\n",
    "        new_df['Cluster'] = [-1]*len(new_df)\n",
    "\n",
    "        #get events that are clustered\n",
    "        row = 0\n",
    "        events = 1\n",
    "        cluster = [row]\n",
    "        cluster_num = 0\n",
    "\n",
    "        while (row < len(self.eventdf)):\n",
    "\n",
    "            #make sure there is a next event. if at end of dataframe, set times to fail next test\n",
    "            if(row < len(self.eventdf) - 1):\n",
    "                successive_time = sorted_df.iloc[row + 1]['MaxTime'] #+ sorted_df.iloc[row + 1]['MaxPosInWindow']/1000.0\n",
    "                event_time = sorted_df.iloc[row]['MaxTime'] #+ sorted_df.iloc[row]['MaxPosInWindow']/1000.0\n",
    "            else:\n",
    "                event_time = 0\n",
    "                successive_time = t_thresh + 1\n",
    "\n",
    "\n",
    "            if abs(successive_time - event_time) <= t_thresh:\n",
    "                events += 1\n",
    "                cluster.append(row + 1)\n",
    "            else:   \n",
    "\n",
    "                #print(events)\n",
    "                if events < e_thresh:\n",
    "                    for i in cluster:\n",
    "                        new_df = new_df.drop(i) #sorted_df.index[i])\n",
    "                else:\n",
    "                    #clusters.append(cluster)\n",
    "                    for i in cluster:\n",
    "                        #print(cluster_num)\n",
    "                        new_df.loc[i, 'Cluster'] = cluster_num\n",
    "                    cluster_num += 1\n",
    "\n",
    "                events = 1\n",
    "                cluster = [row + 1]\n",
    "\n",
    "            row += 1\n",
    "        \n",
    "        self.eventdf = new_df\n",
    "    \n",
    "        return self\n",
    "\n",
    "\n",
    "    # create dictionary mapping channel numbers to a tuple containing coordinates (x,y,z)\n",
    "    def load_coords(self):\n",
    "\n",
    "        coords = {}\n",
    "\n",
    "        with open(pwd + \"/data/detector_positions.txt\", 'r') as f:\n",
    "            for line in f:\n",
    "                data = line.split(',')\n",
    "\n",
    "                if int(data[0]) < 1000:\n",
    "                    coords[int(data[0])] = (float(data[1]), float(data[2]), float(data[3]))\n",
    "\n",
    "        return coords\n",
    "\n",
    "    # returns array of 3 arrays corresponding to x y z\n",
    "    def clustercoords(self, cluster):\n",
    "\n",
    "        #coords = []\n",
    "        x = []\n",
    "        y = []\n",
    "        z = []\n",
    "\n",
    "        for c in cluster['Channel']:\n",
    "            #coords.append([ch_coords[c][0], ch_coords[c][1], ch_coords[c][2]])\n",
    "            x.append(self.coords[c][0])\n",
    "            y.append(self.coords[c][1])\n",
    "            z.append(self.coords[c][2])\n",
    "\n",
    "        return [x,y,z]\n",
    "\n",
    "    \n",
    "    # takes dataframe of a single cluster and finds line of best fit\n",
    "    def basicfit(self, cluster):\n",
    "        coords = self.clustercoords(cluster)\n",
    "\n",
    "        data  = np.array(coords).T\n",
    "\n",
    "        datamean = data.mean(axis=0)\n",
    "\n",
    "        # Do an SVD on the mean-centered data.\n",
    "        uu, dd, vv = np.linalg.svd(data - datamean)\n",
    "\n",
    "        linepts = vv[0] * np.mgrid[-400:400:2j][:, np.newaxis]\n",
    "\n",
    "        # shift by the mean to get the line in the right place\n",
    "        linepts += datamean\n",
    "\n",
    "        #return linepts\n",
    "        return (datamean, vv[0])\n",
    "    \n",
    "       \n",
    "    def ptsfromline(self, pts, linepts):\n",
    "    \n",
    "        dlist = []\n",
    "\n",
    "        a = linepts[0]\n",
    "        b = linepts[1]\n",
    "\n",
    "        for i in range(len(pts[0])):\n",
    "            \n",
    "            p = np.array([pts[0][i], pts[1][i], pts[2][i]])            \n",
    "            d = np.linalg.norm(cross(p-a, p-b)) / np.linalg.norm(b-a)\n",
    "\n",
    "            dlist.append(d)\n",
    "\n",
    "        return dlist\n",
    "\n",
    "    \n",
    "    # x = [p0,p1,p2,v0,v1,v2]\n",
    "    def cost (self, x, hit_pts, miss_pts): \n",
    "        cubeLength = 50\n",
    "        inside = cubeLength/2*np.sqrt(3)\n",
    "\n",
    "        p = x[:3]\n",
    "        v = x[3:]\n",
    "\n",
    "        linepts = v * np.mgrid[-.5:.5:2j][:, np.newaxis] + p\n",
    "\n",
    "        hitlist = ptsfromline(hit_pts, linepts)\n",
    "\n",
    "        if len(miss_pts) == 0:\n",
    "            #print('here')\n",
    "            return sum([1/(1 + np.exp(-.1*(d-inside))) for d in hitlist])\n",
    "\n",
    "        misslist = ptsfromline(miss_pts, linepts)\n",
    "\n",
    "        #return sum([d**2 for d in hitlist]) + sum([inside**4/d**2 for d in misslist])\n",
    "        \n",
    "        return sum([1/(1 + np.exp(-.1*(d-inside))) for d in hitlist]) + sum([1/(1 + np.exp(.1*(d-inside))) for d in misslist])\n",
    "\n",
    "\n",
    "    \n",
    "    # takes dataframe of a single cluster and finds line of best fit\n",
    "    def fitline(self, cluster, trials = 20, steps=200, eps=1e-6):\n",
    "        \n",
    "        p0, v0 = basicfit(cluster)\n",
    "\n",
    "        linepts = v0 * np.mgrid[-400:400:2j][:, np.newaxis] + p0\n",
    "\n",
    "        #cost(np.append(vv[0], datamean))\n",
    "        #x = np.ones(6)\n",
    "        x = np.append(p0, v0)\n",
    "\n",
    "        first_hit_chs, first_miss_chs = self.channelcollisions(linepts)\n",
    "\n",
    "        want_to_hit_chs = cluster['Channel'].values\n",
    "        want_to_miss_chs = [ch for ch in first_hit_chs if ch not in want_to_hit_chs]\n",
    "\n",
    "        for i in range(trials):\n",
    "            \n",
    "            linepts = x[3:] * np.mgrid[-400:400:2j][:, np.newaxis] + x[:3]\n",
    "            hit_chs, miss_chs = self.channelcollisions(linepts)\n",
    "\n",
    "            for ch in miss_chs:\n",
    "                if ch not in want_to_hit_chs and ch not in want_to_miss_chs:\n",
    "                    want_to_miss_chs.append(ch)\n",
    "                    #print(want_to_miss_chs)\n",
    "\n",
    "\n",
    "            hit_pts = np.array([da.coords[channel] for channel in want_to_hit_chs]).T\n",
    "            miss_pts = np.array([da.coords[channel] for channel in want_to_miss_chs]).T\n",
    "\n",
    "            if len(want_to_miss_chs) == 0:\n",
    "                return linepts\n",
    "\n",
    "            for j in range(steps):\n",
    "\n",
    "                g = sc.optimize.approx_fprime(x, cost, [eps]*3 + [eps]*3, hit_pts, miss_pts)\n",
    "\n",
    "                #print(g)\n",
    "                x -= g*eps\n",
    "\n",
    "        p = x[:3]\n",
    "        v = x[3:] / np.linalg.norm(x[3:])\n",
    "\n",
    "        betterlinepts = v * np.mgrid[-400:400:2j][:, np.newaxis] + p\n",
    "    \n",
    "        return betterlinepts\n",
    "    \n",
    "    \n",
    "    \n",
    "    def clusterNRMSE(self, cluster):\n",
    "        ''' gets NRMSE for a given cluster\n",
    "            use distance from point to line of best fit as residual where\n",
    "            d = |(p-a)x(p-b)|/|b-a|\n",
    "            and variables are vectors'''\n",
    "        \n",
    "        if len(cluster) <= 2:\n",
    "            return 0\n",
    "\n",
    "        dlist = []\n",
    "        \n",
    "        # store 2 best fit lines as vectors\n",
    "        linepoints = self.fitline(cluster)\n",
    "        a = linepoints[0]\n",
    "        b = linepoints[1]\n",
    "\n",
    "        for index, event in cluster.iterrows():\n",
    "\n",
    "            p = np.array(self.coords[event['Channel']])\n",
    "            d = np.linalg.norm(cross(p-a, p-b)) / np.linalg.norm(b-a)\n",
    "\n",
    "            dlist.append(d)\n",
    "\n",
    "        # get root mean squared error for cluster\n",
    "        RMSE = math.sqrt(sum([i**2 for i in dlist])/(2* len(dlist) - 4))\n",
    "\n",
    "        # normalize\n",
    "        NRMSE = RMSE / 4.54**2\n",
    "\n",
    "        return NRMSE\n",
    "    \n",
    "    def errorchannels(self,cluster):\n",
    "        \n",
    "        linepoints = self.fitline(cluster)\n",
    "        hitchannels = self.channelcollisions(linepoints)[0]\n",
    "        clusterchannels = cluster['Channel'].unique()\n",
    "        \n",
    "        extra = [ch for ch in hitchannels if ch not in clusterchannels]\n",
    "        missing = [ch for ch in clusterchannels if ch not in hitchannels]\n",
    "        \n",
    "        return (missing, extra)\n",
    "        \n",
    "        \n",
    "    def zenith(self, linepoints):\n",
    "\n",
    "        z = abs(linepoints[0][2] - linepoints[1][2])\n",
    "        d = abs(np.linalg.norm(linepoints[0] - linepoints[1]))\n",
    "        return math.acos(z/d)\n",
    "    \n",
    "    def azimuth(self, linepoints):\n",
    "\n",
    "        y = linepoints[0][1] - linepoints[1][1]\n",
    "        x = linepoints[0][0] - linepoints[1][0]\n",
    "        \n",
    "        # confine to 1st and 4th quadrant\n",
    "        if x < 0:\n",
    "            y*=-1\n",
    "            x*=-1\n",
    "        \n",
    "        return math.atan2(y, x)\n",
    "    \n",
    "        \n",
    "    def lineplanecollision(self, planeNormal, planePoint, rayDirection, rayPoint, epsilon=1e-6):\n",
    "\n",
    "        ndotu = planeNormal.dot(rayDirection)\n",
    "        if abs(ndotu) < epsilon:\n",
    "            return None\n",
    "\n",
    "        t = -planeNormal.dot(rayPoint - planePoint) / ndotu\n",
    "\n",
    "        return rayPoint + t * rayDirection\n",
    "\n",
    "    \n",
    "    def linecubecollision(self, cubeCenter, cubeLength, rayDirection, rayPoint, epsilon=1e-6):\n",
    "\n",
    "        cubeCollisions = []\n",
    "\n",
    "        halfLength = cubeLength / 2.0\n",
    "\n",
    "        directions = np.array([\n",
    "            [0,0,halfLength], #up\n",
    "            [0,halfLength,0], #front\n",
    "            [halfLength,0,0], #right\n",
    "        ])\n",
    "\n",
    "        planeCollisions = []\n",
    "        for i in range(6):\n",
    "            if i >= 3:\n",
    "                faceNormal = -directions[i%3] # to get down, back, left\n",
    "            else:\n",
    "                faceNormal = directions[i]\n",
    "\n",
    "            facePoint = cubeCenter + faceNormal\n",
    "\n",
    "            collision = self.lineplanecollision(faceNormal, facePoint, rayDirection, rayPoint)\n",
    "            if collision is not None:\n",
    "                planeCollisions.append(collision)\n",
    "\n",
    "        #check if intersection is outside cube\n",
    "        for collision in planeCollisions:\n",
    "\n",
    "            inside = True\n",
    "            for i in range(3):\n",
    "                if collision[i] > (cubeCenter[i] + halfLength + epsilon) or collision[i] < (cubeCenter[i] - halfLength - epsilon):\n",
    "                    inside = False\n",
    "\n",
    "            if inside:\n",
    "                cubeCollisions.append(collision)\n",
    "\n",
    "        return cubeCollisions\n",
    "    \n",
    "    \n",
    "    def channelcollisions(self, linepoints, epsilon=1e-6):\n",
    "                \n",
    "        rayDirection = linepoints[1] - linepoints[0]\n",
    "        rayPoint = linepoints[0]\n",
    "        cubeLength = 50\n",
    "                \n",
    "        #start = time.time()\n",
    "        \n",
    "        hit_channels = []\n",
    "        miss_channels = []\n",
    "        \n",
    "        for channel in range(1,len(self.coords)+1):\n",
    "            cubeCenter = self.coords[channel]\n",
    "\n",
    "            #check if cubeCenter is within range of line\n",
    "            CP = cubeCenter - linepoints[0]\n",
    "            distance_to_line = np.abs(np.linalg.norm(cross(CP,rayDirection)) / np.linalg.norm(rayDirection))\n",
    "\n",
    "            #print(distance_to_line)\n",
    "\n",
    "            if distance_to_line < cubeLength/2*np.sqrt(3) + epsilon:\n",
    "            #if distance_to_line < cubeLength*np.sqrt(3) + epsilon:\n",
    "\n",
    "                collision = self.linecubecollision(cubeCenter, cubeLength, rayDirection, rayPoint)\n",
    "                if len(collision) == 2:\n",
    "                    hit_channels.append(channel)\n",
    "                else:\n",
    "                    miss_channels.append(channel)\n",
    "                    \n",
    "        return (hit_channels, miss_channels)\n",
    "       \n",
    "    \n",
    "    def make_clusterdf(self):\n",
    "        # get clusters\n",
    "        clusters = np.unique(self.eventdf['Cluster'])\n",
    "        numofclusters = len(clusters)\n",
    "\n",
    "        eventspercluster = []\n",
    "        channelspercluster = []    \n",
    "        starttimes = []\n",
    "        timespreads = []\n",
    "        NRMSE = []\n",
    "        extrachannels = []\n",
    "        missingchannels = []\n",
    "        zeniths = []\n",
    "        azimuths = []\n",
    "        \n",
    "        \n",
    "        for c in range(numofclusters):\n",
    "\n",
    "            cluster = self.eventdf[self.eventdf['Cluster'] == c]\n",
    "\n",
    "            #event and channel info\n",
    "            eventspercluster.append(len(cluster))\n",
    "            channelspercluster.append(len(cluster['Channel'].unique()))\n",
    "\n",
    "            #get timespread\n",
    "            clustertimes = cluster['MaxTime']\n",
    "            starttimes.append(min(clustertimes))\n",
    "            timespreads.append(max(clustertimes) - min(clustertimes))\n",
    "\n",
    "            #get NRMSE\n",
    "            NRMSE.append(self.clusterNRMSE(cluster))\n",
    "                        \n",
    "            #get missing and extra channels\n",
    "            missing, extra = self.errorchannels(cluster)\n",
    "            \n",
    "            extrachannels.append(len(extra))\n",
    "            missingchannels.append(len(missing))\n",
    "            \n",
    "            #get angles\n",
    "            linepoints = self.fitline(cluster)\n",
    "            zeniths.append(self.zenith(linepoints))\n",
    "            azimuths.append(self.azimuth(linepoints))\n",
    "        \n",
    "        #zeniths_degrees = [theta*360/(2*math.pi) for theta in zeniths]\n",
    "        #cos_theta = [math.cos(theta) for theta in zeniths]\n",
    "\n",
    "        d = {'Cluster' : clusters, 'Events' : eventspercluster, 'Channels' : channelspercluster, \\\n",
    "            'StartTime': starttimes, 'TimeSpread' : timespreads, 'NRMSE' : NRMSE, \\\n",
    "             'Zenith' : zeniths,'Azimuth': azimuths, 'ExtraCh': extrachannels, 'MissingCh' : missingchannels}\n",
    "\n",
    "        newdf = pd.DataFrame(data=d)\n",
    "\n",
    "        #return newdf\n",
    "        self.clusterdf = newdf\n",
    "        \n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def filter_clusterdf(self, NRMSE, channels):\n",
    "        self.clusterdf = self.clusterdf[self.clusterdf['NRMSE'] < NRMSE]\n",
    "        self.clusterdf = self.clusterdf[self.clusterdf['Channels'] >= channels]\n",
    "        \n",
    "        return self\n",
    "\n",
    "\n",
    "    def get_clusterdf(self):\n",
    "        return self.clusterdf\n",
    "    \n",
    "    \n",
    "    def get_clusterrate(self):\n",
    "        \n",
    "        num_clusters = len(self.clusterdf)\n",
    "\n",
    "        # fix times\n",
    "        with open(pwd + \"/data/ds3564_start_stop_times.txt\") as f:\n",
    "            f.readline()\n",
    "            f.readline()\n",
    "\n",
    "            first = True\n",
    "\n",
    "            sum = timedelta()\n",
    "\n",
    "            for line in f:\n",
    "                linedata = line.split('|')\n",
    "                linedata = [i.lstrip().rstrip() for i in linedata]\n",
    "\n",
    "                if linedata[2] == \"Background\" and linedata[6] == \"OK (0)\":\n",
    "\n",
    "                    (h, m, s) = linedata[5].split(':')\n",
    "                    d = timedelta(hours=int(h), minutes=int(m), seconds=int(s))\n",
    "                    sum += d\n",
    "\n",
    "        total_seconds = sum.total_seconds()\n",
    "\n",
    "        return float(num_clusters) / float(total_seconds)\n",
    "    \n",
    "    \n",
    "    def get_cluster(self, cluster_num):\n",
    "        return self.eventdf[self.eventdf['Cluster'] == cluster_num]\n",
    "    \n",
    "    \n",
    "    def show_channel(self, channel_list, x1=15, x2=45):\n",
    "        plt.figure(figsize=(10,10))\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.set_proj_type('ortho')\n",
    "        \n",
    "        if isinstance(channel_list, (int, np.int64)):\n",
    "            channel_list = [channel_list]\n",
    "            \n",
    "        coords = np.array([self.coords[ch] for ch in channel_list]).T\n",
    "        ax.scatter3D(*coords)\n",
    "        \n",
    "        plt.xlim([-350,350])\n",
    "        plt.ylim([-350,350])\n",
    "        ax.set_zlim([-350,350])\n",
    "\n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('y')\n",
    "        ax.set_zlabel('z')\n",
    "\n",
    "        ax.view_init(x1, x2)\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "        \n",
    "    def show_cluster(self, cluster_list, x1=15, x2=45):\n",
    "        \n",
    "        plt.figure(figsize=(10,10))\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.set_proj_type('ortho')\n",
    "        \n",
    "        #if given int, make list\n",
    "        if isinstance(cluster_list, (int, np.int64)):\n",
    "            cluster_list = [cluster_list]\n",
    "            \n",
    "        for c in cluster_list:\n",
    "            cluster = self.eventdf[self.eventdf['Cluster'] == c]\n",
    "\n",
    "            coords = self.clustercoords(cluster)\n",
    "            ax.scatter3D(*coords)\n",
    "\n",
    "            line = self.fitline(cluster)\n",
    "            ax.plot3D(*line.T)\n",
    "\n",
    "        plt.xlim([-350,350])\n",
    "        plt.ylim([-350,350])\n",
    "        ax.set_zlim([-350,350])\n",
    "\n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('y')\n",
    "        ax.set_zlabel('z')\n",
    "\n",
    "        ax.view_init(x1, x2)\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    def show_simulation(self, cluster_num, x1=15, x2=45):\n",
    "        \n",
    "        linepoints = self.fitline(self.get_cluster(cluster_num))\n",
    "        hit_channels = self.channelcollisions(linepoints)[0]\n",
    "\n",
    "        hit_channel_coords = np.array([self.coords[channel] for channel in hit_channels])\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.set_proj_type('ortho')\n",
    "\n",
    "        ax.scatter3D(*hit_channel_coords.T)\n",
    "        ax.plot3D(*linepoints.T)\n",
    "\n",
    "        plt.xlim([-350,350])\n",
    "        plt.ylim([-350,350])\n",
    "        ax.set_zlim([-350,350])\n",
    "\n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('y')\n",
    "        ax.set_zlabel('z')\n",
    "\n",
    "        ax.view_init(x1, x2)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "        \n",
    "# manually do crossproduct to avoid numpy overhead for small vectors\n",
    "def cross(a, b):\n",
    "    c = [a[1]*b[2] - a[2]*b[1],\n",
    "         a[2]*b[0] - a[0]*b[2],\n",
    "         a[0]*b[1] - a[1]*b[0]]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
